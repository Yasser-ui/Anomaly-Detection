{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#inputs data preparation\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#model validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Unnamed: 0', 'index', 'Date', 'RBS Id', 'TRAFFIC PS(DL+UL)(Gbits)',\n       'HSDPA Data Volume', 'HSUPA Data Volume',\n       'Cell Traffic Volume DL Speech (Erlang)', 'CS CSSR', 'CS DROP Rate',\n       'PS Call Setup SR', 'PS DROP Rate 2', 'Availability', 'Soft Handover',\n       'Irat CS Handover SR', 'IRAT PS 2', 'throughput', 'CSDR_anomaly'],\n      dtype='object')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"3G_Cells_with_anomalies.csv\")\n",
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly 23\n",
      "Non-anomaly 202\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly = len(df[df.CSDR_anomaly == 1])\n",
    "nonanomaly = len(df[df.CSDR_anomaly == 0])\n",
    "print(\"Anomaly\", anomaly), print('Non-anomaly', nonanomaly)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0      0.847222\n1      1.125000\n2      1.291667\n3      1.486111\n4      0.833333\n         ...   \n220   -0.041667\n221   -0.055556\n222   -0.083333\n223   -0.041667\n224    0.000000\nName: CS DROP Rate, Length: 225, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob_scaler = RobustScaler()\n",
    "df['CS DROP Rate'] = rob_scaler.fit_transform(df['CS DROP Rate'].values.reshape(-1,1))\n",
    "df['CS DROP Rate']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns == 'CS DROP Rate']\n",
    "y = df.loc[:, df.columns == 'CSDR_anomaly']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# Number of anomaly cases\\nanomaly = len(df[df.CSDR_anomaly == 1])\\n\\n# Selecting the indices of the non-anomaly classes\\nanomaly_indices = df[df.CSDR_anomaly == 1].index\\nnonAnomaly_indices = df[df.CSDR_anomaly == 0].index\\n\\n#from all non-anomaly observations, randomly select observations equal to number of anomaly observations\\nrandom_nonAnomaly_indices = np.random.choice(nonAnomaly_indices, anomaly, replace=False)\\nrandom_nonAnomaly_indices = np.array(random_nonAnomaly_indices)\\n\\n# appending the 2 indices\\nunder_sample_indices = np.concatenate([anomaly_indices, random_nonAnomaly_indices])\\n\\n# underSample dataset\\nunder_sample_data = df.iloc[under_sample_indices,:]\\n\\n# now split X, y variables from the under sample data\\nX_underSample = under_sample_data.loc[:, under_sample_data.columns == 'CS DROP Rate']\\ny_underSample = under_sample_data.loc[:, under_sample_data.columns == 'CSDR_anomaly']\\n\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Number of anomaly cases\n",
    "anomaly = len(df[df.CSDR_anomaly == 1])\n",
    "\n",
    "# Selecting the indices of the non-anomaly classes\n",
    "anomaly_indices = df[df.CSDR_anomaly == 1].index\n",
    "nonAnomaly_indices = df[df.CSDR_anomaly == 0].index\n",
    "\n",
    "#from all non-anomaly observations, randomly select observations equal to number of anomaly observations\n",
    "random_nonAnomaly_indices = np.random.choice(nonAnomaly_indices, anomaly, replace=False)\n",
    "random_nonAnomaly_indices = np.array(random_nonAnomaly_indices)\n",
    "\n",
    "# appending the 2 indices\n",
    "under_sample_indices = np.concatenate([anomaly_indices, random_nonAnomaly_indices])\n",
    "\n",
    "# underSample dataset\n",
    "under_sample_data = df.iloc[under_sample_indices,:]\n",
    "\n",
    "# now split X, y variables from the under sample data\n",
    "X_underSample = under_sample_data.loc[:, under_sample_data.columns == 'CS DROP Rate']\n",
    "y_underSample = under_sample_data.loc[:, under_sample_data.columns == 'CSDR_anomaly']\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yasser\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0], dtype=int64)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        62\n",
      "           1       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.93        68\n",
      "   macro avg       0.78      0.73      0.75        68\n",
      "weighted avg       0.92      0.93      0.92        68\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[60  2]\n",
      " [ 3  3]]\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "classification_report = classification_report(y_test, y_pred)\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
